<img src="https://cdn.lynda.com/course/496940/496940-637473497083962672-16x9.jpg" width=150 height=84 align="right"/>


# [Apache Spark by Example](https://www.linkedin.com/learning/apache-pyspark-by-example/)
Want to get up and running with Apache Spark as soon as possible? If you're well versed in Python, the Spark Python API (PySpark) is your ticket to accessing the power of this hugely popular big data platform. 

This practical, hands-on course helps you get comfortable with PySpark, explaining what it has to offer and how it can enhance your data science work. To begin, instructor Jonathan Fernandes digs into the Spark ecosystem, detailing its advantages over other data science platforms, APIs, and tool sets. Next, he looks at the DataFrame API and how it's the platform's answer to many big data challenges. 

Finally, he goes over Resilient Distributed Datasets (RDDs), the building blocks of Spark. Learning objectives Benefits of the Apache Spark ecosystem Working with the DataFrame API Working with columns and rows Leveraging built-in Spark functions Creating your own functions in Spark Working with Resilient Distributed Datasets (RDDs)

**Learning objectives**
- Benefits of the Apache Spark ecosystem
- Working with the DataFrame API
- Working with columns and rows
- Leveraging built-in Spark functions
- Creating your own functions in Spark
- Working with Resilient Distributed Datasets (RDDs)


Certificate:

![Certificate](https://raw.githubusercontent.com/kavyajeetbora/big-data-spark-linkedin/main/CertificateOfCompletion_Apache%20PySpark%20by%20Example%20(1)_1.jpg)
